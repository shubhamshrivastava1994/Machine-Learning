# -*- coding: utf-8 -*-
"""ML_Project (2)_shubham.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11PEFi2ICrT_xOMhC0T3OWbXbblENCPnF

# Data Analysis
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/drive')



df=pd.read_csv('/drive/My Drive/Datasets/Placement_Data.csv')

df

"""**Check the first four rows of the dataframe**"""

df.head(4)

"""1.sl_no : Serial Number,

2.ssc_p : Secondary Education percentage- 10th Grade

3.ssc_b : Board of Education- Central/ Others

4.hsc_p : Higher Secondary Education percentage- 12th Grade

5.hsc_b : Board of Education- Central/ Others

6.hsc_s : Specialization in Higher Secondary Education

7.degree_p : Degree Percentage

8.degree_t : Under Graduation(Degree type)- Field of degree education

9.workex : Work Experience

10.etest_p : Employability test percentage ( conducted by college)

11.specialisation : Post Graduation(MBA)- Specialization

12.mba_p : MBA percentage

13.status : Status of placement- Placed/Not placed

14.salary : Salary if the student is placed

**Get all feature names**
"""

df.columns

"""**Find the number of records and columns**"""

df.shape

"""**Use the .info() method to find the number of Non Null entries and Data Type of each feature**"""

df.info()

"""**What is the average Secondary Education percentage - 10th Grade**"""

df['ssc_p'].mean()

"""**What is the max Secondary Education percentage - 10th Grade**"""

df['ssc_p'].max()

"""**How many toppers where there in 10th Grade?**

"""

df[df['ssc_p']==df['ssc_p'].max()].shape[0]

"""**Is the student who got highest Secondary Eduaction percentage, placed or not?**

"""

df[df['ssc_p']==df['ssc_p'].max()]['status']

"""**How many students are placed or unplaced?**"""

df['status'].value_counts()

148/215



"""**What is the most common degree of the placed students?**"""

df[df['status']=='Placed']['degree_t'].value_counts().head(1)

"""
**How many unique degrees are there in the dataset?**"""

df['degree_t'].nunique()

"""**Is there a correlation between 10th and 12th percentage**"""

df[['ssc_p','hsc_p']].corr()

"""**Find the correlation matrix**?

"""

df.corr()

"""# Data Pre-processing

**Identify the column which can be removed?(only 1)**

**Remove the unnecessary column**
"""

df.drop(columns=['sl_no'], inplace=True)

df

"""When inplace = True , the data is modified in place, which means it will return nothing and the dataframe is now updated. When inplace = False , which is the default, then the operation is performed and it returns a copy of the object.

**Check number of null values in each column**
"""

df.isnull().sum()

"""**Fill the missing values with appropriate values and check number of null values in each column again**"""

df.fillna(0, inplace=True)

df

"""# Data Visualization

**Import matplotlib and seaborn**
"""

import matplotlib.pyplot as plt
import seaborn as sns

"""**Draw a scatter plot between 10th and 12th percentage with labels and title**"""



plt.scatter(df['ssc_p'],df['hsc_p'])
plt.xlabel("10th percentage")
plt.ylabel("12th percentage")
plt.title("Scatter plot between 10th and 12th percentage")

"""**Draw the scatter plot between 10th and 12th class percentage of students grouped based on placement data**"""

colors={'Placed':'tab:green','Not Placed':'tab:red'}
df['status'].map(colors)

colors={'Placed':'tab:green','Not Placed':'tab:red'}
plt.scatter(df['ssc_p'],df['hsc_p'],c=df['status'].map(colors))
plt.xlabel("10th percentage")
plt.ylabel("12th percentage")
plt.title("Scatter plot between 10th and 12th percentage")

"""**Draw the pairplots between all continuous columns**"""

sns.pairplot(df)

sns.pairplot(df,hue='status', diag_kind='hist')

"""**Draw a boxplot for 10th percentage of the students**"""



sns.boxplot(y='ssc_p', data=df)

"""**Draw a boxplot for 12th percentage of the students**"""

sns.boxplot(y='hsc_p',data=df)

"""**Draw a boxplot for 12th percentage of the students for placed and unplaced students**"""

sns.boxplot(y='hsc_p',data=df, x='status')

y=[1,2,3,76,5,6]
plt.plot(y,label="points on Y")
plt.legend()

"""**Draw lineplot for 10th, 12th, degree and MBA percentage**"""

plt.plot(df['hsc_p'], label="12th")
plt.plot(df['degree_p'], label="degree")
plt.legend()

"""**Find correlation between continous columns**"""

df.corr()

"""**Draw heatmap of correlation**

heatmap visualization or heatmap data visualization is a method of graphically representing numerical data where the value of each data point is indicated using colors.
"""

sns.heatmap(df.corr(), annot=True)



"""**Draw histogram for salary of students**"""

plt.hist(df['salary'])

"""**Draw the distribution of 10th Grade percentage**"""

sns.kdeplot(df['ssc_p'])

df.columns

"""# Outlier Analysis"""

df

sns.boxplot(y='degree_p', data=df)

percentile25=df['degree_p'].quantile(0.25)

percentile25

percentile75=df['degree_p'].quantile(0.75)

iqr=percentile75-percentile25

iqr

percentile75

upper_limit=percentile75+(1.5*iqr)
lower_limit=percentile25-(1.5*iqr)

upper_limit

lower_limit

df=df[(df['degree_p']<upper_limit) & (df['degree_p']>lower_limit)]

sns.boxplot(y='degree_p', data=df)

df.columns

col=['ssc_p','hsc_p','etest_p','mba_p','salary']
for c in col:
  percentile25=df[c].quantile(0.25)
  percentile75=df[c].quantile(0.75)
  iqr=percentile75-percentile25
  upper_limit=percentile75+(1.5*iqr)
  lower_limit=percentile25-(1.5*iqr)
  df=df[(df[c]<upper_limit) & (df[c]>lower_limit)]
  plt.figure()
  sns.boxplot(y=c, data=df)

"""# Label Encoding"""

df

from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()

df['ssc_b']

df['ssc_b']=le.fit_transform(df['ssc_b'])

df['ssc_b']

df

df.columns

col=['gender', 'hsc_b', 'hsc_s', 'degree_t', 'workex', 'specialisation', 'status']

for c in col:
  df[c]=le.fit_transform(df[c])

df

"""# Class 7

**Extract the independent and dependent variables**
"""

X=df.iloc[:,0:-1].values

Y=df.iloc[:,-1].values

X

Y

"""**Split the dataset into training and testing**

"""

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.3,random_state=4)

"""**Use standardization for feature scaling**"""

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

X_train=sc.fit_transform(X_train)

X_train

X_test=sc.transform(X_test)

"""**Perform Linear Regression**"""

from sklearn.linear_model import LinearRegression

reg=LinearRegression()

reg.fit(X_train, Y_train)

reg.intercept_

reg.coef_

Y_pred=reg.predict(X_test)

Y_pred

Y_test

"""**Evaluate the model using MSE, RMSE and R square**"""

from sklearn import metrics

MSE=metrics.mean_squared_error(Y_test, Y_pred)

RMSE=np.sqrt(MSE)

RMSE

R2=metrics.r2_score(Y_test,Y_pred)

R2

